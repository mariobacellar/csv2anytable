# Informe a pasta que conterá as pastas que devem ser monitoradas. 
# Deverá existir 2 niveis de pastas dentro desta, informando a origem (Ex: shinobi) e o tipo do csv (Ex: atendimento)
# Para apagar a respectiva tabela e importar todo o CSV, coloque o CSV na estrtutura: Ex: <datalake.folder.home>/<datalake.folder.csv.load.full>/shinobi/atendimento
# Para adicionar os registros do CSV na respectiva tabela, coloque o CSV na estrtutura: Ex: <datalake.folder.home>/<datalake.folder.csv.load.incremental>/shinobi/atendimento 
datalake.folder.home=/home/mario/Downloads/tableau/arquivos

# Se o valor = '1' a aplicação irá monitorar arquivos CSV gravados em 2 níveis a partir da pasta  <datalake.folder.home>
# Ex: <datalake.folder.home>/<datalake.folder.csv.load.full>/shinobi/atendimento 
# Se o valor = '0' a aplicação irá monitorar arquivos CSV gravados  <datalake.folder.csv.load.full.new>
# Nesse caso o arquivo precisa ter a seguinte nomenclarura <origem>_<tipo>_?????????.csv . Ex: shinobi_atendimento_RELATORIO_2021_01_01.csv
# Onde: 
# - <origem> = shinobi, facebook, ....
# - <tipo> = atendimento, venda, ligacao, ...
# - ????????? = qualquer coisa
# - .csv = para identificar que o arquivo é do tipo CSV
datalake.probe.folder.subnivel=0

datalake.folder.csv.load.full.new=/csv/carga/full
datalake.folder.csv.load.full.old=/csv/processados/full

datalake.folder.csv.load.incremental.new=/csv/carga/incremental
datalake.folder.csv.load.incremental.old=/csv/processados/incremental

# Para que a aplicação pare, informar != "on"
datalake.probe.status=on

# Intervalo entre os monitoramentos dos arquivos CSV
datalake.probe.interval.segundos=5


datalake.folder.origens=shinobi;facebook;macro;googleads;algar;americanet;sky;totalben;ituran;athena;hive;salesforce
datalake.folder.types=atendimento;ligacao;venda;pedido;campanha;localidade

# GCP - Dev - Postgres
# datalake.datasource.url=jdbc:postgresql://34.95.166.158/postgres?sslmode=disable
# datalake.datasource.username=macro-datalake
# datalake.datasource.password=******
# datalake.datasource.driver.class.name=org.postgresql.Driver

# GCP - Dev - datalake
#datalake.datasource.url=jdbc:postgresql://34.95.166.158/datalake?sslmode=disable
#datalake.datasource.username=macro-datalake
#datalake.datasource.password==******
#datalake.datasource.driver.class.name=org.postgresql.Driver

# GCP - Prod - datalake
#datalake.datasource.url=jdbc:postgresql://35.198.56.160/datalake?sslmode=disable
#datalake.datasource.username=macro-datalake
#datalake.datasource.password==******
#datalake.datasource.driver.class.name=org.postgresql.Driver

# Heroku
#datalake.datasource.url=jdbc:postgresql://ec2-54-90-55-211.compute-1.amazonaws.com:5432/degsh157i7aurk?sslmode=require
#datalake.datasource.username=yfjdkgundlwhhl
#datalake.datasource.password==******
#@datalake.datasource.driver.class.name=org.postgresql.Driver


# Heroku
datalake.datasource.url=jdbc:postgresql://ec2-44-194-145-230.compute-1.amazonaws.com:5432/d6uvpssd3i6vn9?sslmode=require
datalake.datasource.username=fnrrovtwkqwkot
datalake.datasource.password==******
@datalake.datasource.driver.class.name=org.postgresql.Driver
